{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix δ = 0:05 (95% confidence) and n = 200. Compute 2q2h log n+h log n 2he +log 2 δ : This is natural log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2278853081842991"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.sqrt(2*((1*np.log(2000) + 1*np.log(2*  2.71828/1) + np.log(2/0.05))/2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999327347282"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(2.71828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.79098117, -0.34841812, -0.49960135,  0.38163654,  0.07296455,\n",
       "         0.55595583, -0.89885683,  0.2526229 , -0.90415984, -0.04743342]),\n",
       " array([0., 0., 0., 1., 1., 1., 0., 1., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(-1,1,10)\n",
    "y = np.zeros(10)\n",
    "ind = np.asarray(np.argwhere(x > 0))[:,0]\n",
    "y[ind] = 1\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07296455220272935"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(x[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.89885683,  0.55595583,  0.07296455, -0.49960135])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERM(count=1, S=10):\n",
    "    error = []\n",
    "    \n",
    "    for i in range(count):\n",
    "        x = np.random.uniform(-1,1,S)\n",
    "        y = np.zeros(S)\n",
    "        ind = np.asarray(np.argwhere(x > 0))[:,0]\n",
    "        y[ind] = 1\n",
    "        error.append(min(x[ind])/2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ERM(count=10000, S=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046899321253292325"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001485342948643242"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.asarray(ans), 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ans, bins=100)\n",
    "plt.ylabel('histogram');\n",
    "plt.title('histogram plot');\n",
    "plt.savefig(\"q2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01488647466511309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.asarray(ans), 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the states\n",
    "location_to_state = {\n",
    "    'A' : 0,\n",
    "    'B' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "gamma = 0.9 # Discount factor \n",
    "alpha = 0.5 # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the actions\n",
    "actions = [0,1]  # \"move\" and \"stay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rewards\n",
    "rewards = np.array([[1,0],\n",
    "                    [0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps indices to locations\n",
    "state_to_location = dict((state,location) for location,state in location_to_state.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------Q-Learning algorithm-----------\n",
    "\n",
    "# Initializing Q-Values\n",
    "Q = np.array(np.zeros([2,2]))\n",
    "Qf = np.array(np.zeros([2,2]))\n",
    "#The agent starts in state s1 = A\n",
    "current_state = 0\n",
    "#print(state_to_location[current_state])\n",
    "\n",
    "for i in range(200):\n",
    "    #actions = np.random.randint(0,2)\n",
    "    n = random.random()\n",
    "    if n < 0.5:\n",
    "        actions = 0\n",
    "    else:\n",
    "        actions = 1\n",
    "    if actions == 1:\n",
    "        next_state = current_state\n",
    "    else:\n",
    "        if current_state == 0:\n",
    "            next_state = 1\n",
    "        else:\n",
    "            next_state = 0\n",
    "    \n",
    "    #print(state_to_location[current_state], state_to_location[next_state])\n",
    "    \n",
    "    Q[current_state,next_state] = (1-alpha)*Q[current_state,next_state] + alpha*(rewards[current_state,next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])])\n",
    "    current_state = next_state\n",
    "Qf[0,1] = Q[0,0]\n",
    "Qf[0,0] = Q[0,1]\n",
    "Qf[1,1] = Q[1,1]\n",
    "Qf[1,0] = Q[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.47358857, 9.23064391],\n",
       "       [8.27699814, 9.43438373]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.87491817, 9.35634351],\n",
       "       [8.36362713, 9.88466698]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing Q-Values\n",
    "Q = np.array(np.zeros([2,2]))\n",
    "Qf = np.array(np.zeros([2,2]))\n",
    "#The agent starts in state s1 = A\n",
    "current_state = 0\n",
    "#print(state_to_location[current_state])\n",
    "\n",
    "for i in range(200):\n",
    "    #actions = np.random.randint(0,2)\n",
    "    n = random.random()\n",
    "    if n < 0.5:\n",
    "        actions = np.argmax(Q[current_state,:])\n",
    "    else:\n",
    "        actions = np.random.randint(0,2)\n",
    "                            \n",
    "    if actions == 1:\n",
    "        next_state = current_state\n",
    "    else:\n",
    "        if current_state == 0:\n",
    "            next_state = 1\n",
    "        else:\n",
    "            next_state = 0\n",
    "    \n",
    "    #print(state_to_location[current_state], state_to_location[next_state])\n",
    "    \n",
    "    Q[current_state,next_state] = (1-alpha)*Q[current_state,next_state] + alpha*(rewards[current_state,next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])])\n",
    "    current_state = next_state\n",
    "Qf[0,1] = Q[0,0]\n",
    "Qf[0,0] = Q[0,1]\n",
    "Qf[1,1] = Q[1,1]\n",
    "Qf[1,0] = Q[1,0]\n",
    "Qf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing Q-Values\n",
    "Q = np.array(np.zeros([2,2]))\n",
    "Qf = np.array(np.zeros([2,2]))\n",
    "#The agent starts in state s1 = A\n",
    "current_state = 0\n",
    "#print(state_to_location[current_state])\n",
    "\n",
    "for i in range(200):\n",
    "    #actions = np.random.randint(0,2)\n",
    "\n",
    "    actions = np.argmax(Q[current_state,:])\n",
    "                          \n",
    "    if actions == 1:\n",
    "        next_state = current_state\n",
    "    else:\n",
    "        if current_state == 0:\n",
    "            next_state = 1\n",
    "        else:\n",
    "            next_state = 0\n",
    "    \n",
    "    #print(state_to_location[current_state], state_to_location[next_state])\n",
    "    \n",
    "    Q[current_state,next_state] = (1-alpha)*Q[current_state,next_state] + alpha*(rewards[current_state,next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])])\n",
    "    current_state = next_state\n",
    "Qf[0,1] = Q[0,0]\n",
    "Qf[0,0] = Q[0,1]\n",
    "Qf[1,1] = Q[1,1]\n",
    "Qf[1,0] = Q[1,0]\n",
    "Qf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
